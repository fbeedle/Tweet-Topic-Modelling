{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file('coversheet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f768562d-51e1-4728-b165-b2bbc8220553",
   "metadata": {},
   "source": [
    "# Modelling changes in Bitcoin tweets over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ea2ea-0203-4d46-9b6d-e512ea7cc02c",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5572b0f-784c-4935-b5a2-8141ab0ac762",
   "metadata": {},
   "source": [
    "Bitcoin's prominence as a leading cryptocurrency has prompted a huge amount of discource on social media platforms. However, its price is also known to be volatile, with fluctations caused by a wide range of factors. This project aims to uncover the topics relating Bitcoin in tweets, and explore how these topics vary over time and whether these changes align when compared the Bitcoin's trade value.\n",
    "\n",
    "The results of this have been... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132bdea5-0bad-4c70-a2e3-e173a30f3fc1",
   "metadata": {},
   "source": [
    "## Introduction and literature review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d781ebdb-6147-4515-b700-eb4e8a1d7f66",
   "metadata": {},
   "source": [
    "Bitcoin has proven to be the most widely known and heavily traded cryptocurrency, with recent research from the Financial Conduct Authority (FCA) revealing that 78% of respondants surveyed had heard of it and that 60% of those trading in cryptocurrencies held the asset [[1]](#ref1). Because of this rise to prominence, Bitcoin has become economically and culturally significant. However, it has also generated a large amount of controversies and criticism stemming from its negative impact on the environment, lack of regulation and from its price volatility making investments risky [[2]](#ref2). All of these properties generate discourse and fuel discussions on social media, which can be used as a yardstick to measuring public perception towards Bitcoin as news and changes are reported. \n",
    "\n",
    "The key themes within these discussions can be summarised using topic modelling techniques. There is extensive literature detailing the effectiveness of different methods on social media data. One study used Latent Dirichlet Allocation (LDA) to uncover hidden topics in global warming tweets [[3]](#ref3). However, this paper didn't test other models or tailor the process to the data. Ortu et al produced a more detailed review, using LDA in conjunction with the Hawkes model on cryptocurrecy related Reddit posts to identify topic changes which preceded price fluctuations [[4]](#ref4). However, while LDA is very common in topic modelling, its effectiveness on short form data is called into question by a paper by Curiskis et al. A variety of feature representation methods and clustering techniques were tested on tweets, finding that doc2vec word embeddings outperforming tf-idf (term frequency- inverse word frequency), and k means clustering was more effective than LDA on shorter text lengths [[5]](#ref4). \n",
    "\n",
    "More recent word embeddings based models show promise, but also need to be able to monitor changes in topics over time. Bernie et al proposed first identifying word frequency changes during periods of intense crypto price volatility, then applying word2vec models to measuring how distinct the resulting topics were using cosine similarity [[6]](#ref6). While this did find interpretable topics, it also relied on identifying specific time periods of interest in advance, and may less effective when applied over wider time scales. Finally, another study tested the properties and suitability of several different model types for Twitter data, with BERTopic being noted both for its ability to create relevant topics and its adaptability allowing for use as a dynamic topic model [[7]](#ref7).\n",
    "\n",
    "Research has also been conducted into the best methods to process tweets for modelling. While they provide a huge number of observations for study, each individual post is by nature is very short, making the extraction of meaningful topics difficult. As well as this, they are known to include high levels of noise, which can be a barrier to effective modelling. Belal et al proposes a solution to this by detailing a number of preprocessing steps in order to improve the quality of short text data, which lead to measurable improvements in classification models on clensed data compared to uncleansed [[8]](#ref8).\n",
    "\n",
    "Given the wide range of methods available, I decided to test how LDA compared against BERTopic to determine the best model to produce interpretable results for my specific data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8f5170-3bc7-4980-b9bf-e5352d8d6752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Fern\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#cleaning\n",
    "import emoji\n",
    "import gensim\n",
    "import re\n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "import spacy\n",
    "import contractions\n",
    "import better_profanity\n",
    "\n",
    "#Analysis\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "\n",
    "#Modelling\n",
    "import gensim.downloader as api\n",
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "#setup\n",
    "nlp = spacy.load(\"en_core_web_md\") #Note- first install model with pip\n",
    "tqdm.pandas() # progress bar for pipeline\n",
    "\n",
    "#Display settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")#remove warnings for html output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f1e92-64e5-4705-9cad-eb69c730b173",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d57e7b-7157-487d-ac78-78f7dbc742a4",
   "metadata": {},
   "source": [
    "I chose to use a large dataset of 4,689,354 tweets which were categorised using the Bitcoin hashtag [[9]](#ref9). I chose this as it included observations over a relatively long time range (from February 2021- January 2023). However, full analysis on this much data would be prohibitively resource intensive and unnecessary for the purposes of this report. Therefore, I examined the data in more detail to retain only the relevant data. The date and tweets themselves were the only useful variables so I adapted the 'read_csv' function to reduce processing times. The data contains no missing values but converting the date format revealed 66 erroneous values to remove.  \n",
    "\n",
    "After examining a random sample of 500 tweets I determined approximately 25% of observations were spam. These took the form of promotional content, links to likely malicious webpages and autogenerated price reports. The prevalence of spam in tweets is well documented and detecting it could form a full project in its own right [[10]](#ref10). However, given the time constraints I instead aimed to filter out as much as possible by removing all duplicates, tweets containing some specific hashtags or which had more than 10 hashtags in total, and used regex patterns to remove trading price tweets. While this may excluse some genuine posts, there were enough observations in the dataset to allow for greedy filtering steps to extract the highest quality data.  \n",
    "\n",
    "The maximum character limit for tweets prior to February 2023 was 280 [[11]](#ref11). While there are longer strings in the dataset, these are caused by high numbers of mentions. Unlikely higher numbers of hashtags, this didn't necessarily indicate spam, so I retained these to be cleaned later. \n",
    "\n",
    "I then took a sample of the remaining documents, giving an even number of 1000 for each date. Some dates included did not contain enough tweets, so were removed entirely.\n",
    "\n",
    "The next step was to handle the noise present within the tweets themselves, including emojis. At first my instinct was to remove the emojis completely, but in the context of Bitcoin they could convey insightful information. For example, the rocket emoji conveying excitment at increasing prices. Instead, I used the 'emoji' package to convert the utf-8 to a text description. I then  removed URLs, HTML tags and mentions, but not hashtagged words as these can convey meaning [[8 pg. 98]]. The informal nature of tweets make slang terms and profanity common so I used the 'better-profanity' library to clean these. These processes were very time intensive, but should result in more interpretable topics. \n",
    "\n",
    "Some of the models then required additional cleaning steps. These involved using the 'spaCY' library to tokenise, remove stopwords, lemmatise the words to their base form, and retain only the nouns, verbs and adjectives from the text. These steps aren't suitable for the BERTopic model as they destroy the sentence structure, but are beneficial for the LDA model, so these formed an additional 'tokens' variable. \n",
    "\n",
    "Finally, in order to compare the changes in topics to changes in Bitcoin value over time I sourced a second dataset from Kaggle which gave the closing prices of Bitcoin over the same time range [[12]]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d566413",
   "metadata": {},
   "source": [
    "#### Examine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bc4980-04c2-473b-b6dc-b1cdc6f6b271",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-10 23:59:04</td>\n",
       "      <td>Blue Ridge Bank shares halted by NYSE after #bitcoin ATM announcement https://t.co/xaaZmaJKiV @MyBlueRidgeBank… https://t.co/sgBxMkP1SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-10 23:58:48</td>\n",
       "      <td>😎 Today, that's this #Thursday, we will do a \"🎬 Take 2\" with our friend @LeoWandersleb, #Btc #wallet #security expe… https://t.co/go6aDgRml5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-10 23:54:48</td>\n",
       "      <td>Guys evening, I have read this article about BTC and would like to share with you all - https://t.co/QxCZgmuy3B… https://t.co/o6wn7ppkVY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-10 23:54:33</td>\n",
       "      <td>$BTC A big chance in a billion! Price: \\4872644.0 (2021/02/11 08:51) #Bitcoin #FX #BTC #crypto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-10 23:54:06</td>\n",
       "      <td>This network is secured by 9 508 nodes as of today. Soon, the biggest bears will recognise: #BTC in too big to fail… https://t.co/1XovDA8rKw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  \\\n",
       "0  2021-02-10 23:59:04   \n",
       "1  2021-02-10 23:58:48   \n",
       "2  2021-02-10 23:54:48   \n",
       "3  2021-02-10 23:54:33   \n",
       "4  2021-02-10 23:54:06   \n",
       "\n",
       "                                                                                                                                           text  \n",
       "0       Blue Ridge Bank shares halted by NYSE after #bitcoin ATM announcement https://t.co/xaaZmaJKiV @MyBlueRidgeBank… https://t.co/sgBxMkP1SI  \n",
       "1  😎 Today, that's this #Thursday, we will do a \"🎬 Take 2\" with our friend @LeoWandersleb, #Btc #wallet #security expe… https://t.co/go6aDgRml5  \n",
       "2      Guys evening, I have read this article about BTC and would like to share with you all - https://t.co/QxCZgmuy3B… https://t.co/o6wn7ppkVY  \n",
       "3                                                $BTC A big chance in a billion! Price: \\4872644.0 (2021/02/11 08:51) #Bitcoin #FX #BTC #crypto  \n",
       "4  This network is secured by 9 508 nodes as of today. Soon, the biggest bears will recognise: #BTC in too big to fail… https://t.co/1XovDA8rKw  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4689354\n",
      " Number of columns: 2\n"
     ]
    }
   ],
   "source": [
    "#Path to file\n",
    "path = \"./Data/Bitcoin_tweets.csv\"\n",
    "\n",
    "#Line terminator required to prevent read error, usecols to extract only relevant information \n",
    "df = pd.read_csv(path, lineterminator='\\n', parse_dates=['date'], usecols = [8,9])\n",
    "display(df.head())\n",
    "print(\"Number of rows: \" + str(df.shape[0]) + \"\\n\",\n",
    "      \"Number of columns: \" + str(df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd367acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max character length: 987\n",
      "Shortest length: 5\n",
      "Average length: 181.0\n"
     ]
    }
   ],
   "source": [
    "#Find characterlengths\n",
    "print(\"Max character length: \" + str(df[\"text\"].str.len().max()) + \"\\n\" +\n",
    "      \"Shortest length: \" +  str(df[\"text\"].str.len().min()) + \"\\n\" +\n",
    "       \"Average length: \" + str(df[\"text\"].str.len().mean().round(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a95d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80423</th>\n",
       "      <td>2021-04-23 11:34:14</td>\n",
       "      <td>@moonMacawNFT @NFTarantulas @RedPandasNFT @StrayAliens @BitAliens @ProudSquirrel @The_HashPunks @MoonicornsNFT @MonstrrrNFT @BastardGhosts @Nifty_Cats @NessiesNFT @Budgiesnft @GloriousCrypto @BitSnails @idiomacy @Skelebits @ProctonsNFT @BitBlobsNFT Tired of the same collections? Looking for something different with a statement behind it? Check out the F*CK FIAT #nft Collectables that represent the historic moment where #BITCOIN defeats FIAT Currency. #btc #lasereyes  #nftcollectables #nftcollectors https://t.co/HvmAnLLlTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131239</th>\n",
       "      <td>2021-06-23 17:45:27</td>\n",
       "      <td>@Davidskylarkk @Lilblubird87 @BallsDeeptheone @Dgord6 @rockthrower19 @SECJackson @SEC_Enforcement @Boston_SEC @SF_SEC @NewYork_SEC @SEC_DERA @HesterPeirce @BarbaraRoper1 @MicahHauptman @NubreedNutritio @BillChaaban @SecretaryCarson @jerryalmufleh @griffpatriot @ewarren @SenWarren @FINRA @lajass @mcervantes1 @GiddyUpRocks This is comedy can we stop concentrating on #bitcoin #cryptocurrency #cryptocurrencies #cryptocrash #robinhoodtraders and #stonks #apes and find  how $fitx shareholder's money was spent enuf #gamestop #amc #wallstreetbets we have our own problems with these #otc #OTCQB Beauties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132621</th>\n",
       "      <td>2021-06-23 16:57:06</td>\n",
       "      <td>@AlgyHall @Gallon73 @wheeliedealer @rcwhalen @HedgeyeTV @dlacalle_IA @Hedgeye @obone747 @MY21_Oracle @slarratt1 @Financial_Orbit @asibiza1 @marxnd @elerianm @TheIdleInvestor @ToddWenning @RobertStGeorge @RobertJShiller @Halsrethink @CiovaccoCapital @TheBubbleBubble @ReformedBroker @contrariansmind @MichaelSchuman @nickbatsford @ReutersJamie @M_McDonough @jonsanchezshow @DianaEPatterson @paul_dobson @KeithMcCullough @andrewrsorkin @FerroTV @MeganCBoxall @philjoakley @ShareScope @HW_MA @achildofthe70s @DVB99 @MacroPoloChina @followingeric @claudiohfox @groupstageexit @chumba54339270 @CarrRosie @marymcdougall13 @IChronicle @cfauk NEW🔥#TwinPetesInvesting #VIDEO #Podcast 51: #INVESTING #RISKS POSITION SIZING #FTSE #AIM #BITCOIN #CRYPTO #DOGECOIN #PSYCHOLOGY #PCA #AHT #BOTB #NWG #LLOY #BARC #DIVIDENDS #EQLS #MTFB #MMAG #CLIN #GTLY #CMRS #CUSN #ROO #AML #TPG #TRADING #SPREADBETTING &amp;amp; https://t.co/FkrDWniXFE https://t.co/zWm6DWqk3p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  \\\n",
       "80423   2021-04-23 11:34:14   \n",
       "131239  2021-06-23 17:45:27   \n",
       "132621  2021-06-23 16:57:06   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \n",
       "80423                                                                                                                                                                                                                                                                                                                                                                                                                                 @moonMacawNFT @NFTarantulas @RedPandasNFT @StrayAliens @BitAliens @ProudSquirrel @The_HashPunks @MoonicornsNFT @MonstrrrNFT @BastardGhosts @Nifty_Cats @NessiesNFT @Budgiesnft @GloriousCrypto @BitSnails @idiomacy @Skelebits @ProctonsNFT @BitBlobsNFT Tired of the same collections? Looking for something different with a statement behind it? Check out the F*CK FIAT #nft Collectables that represent the historic moment where #BITCOIN defeats FIAT Currency. #btc #lasereyes  #nftcollectables #nftcollectors https://t.co/HvmAnLLlTR  \n",
       "131239                                                                                                                                                                                                                                                                                                                                                      @Davidskylarkk @Lilblubird87 @BallsDeeptheone @Dgord6 @rockthrower19 @SECJackson @SEC_Enforcement @Boston_SEC @SF_SEC @NewYork_SEC @SEC_DERA @HesterPeirce @BarbaraRoper1 @MicahHauptman @NubreedNutritio @BillChaaban @SecretaryCarson @jerryalmufleh @griffpatriot @ewarren @SenWarren @FINRA @lajass @mcervantes1 @GiddyUpRocks This is comedy can we stop concentrating on #bitcoin #cryptocurrency #cryptocurrencies #cryptocrash #robinhoodtraders and #stonks #apes and find  how $fitx shareholder's money was spent enuf #gamestop #amc #wallstreetbets we have our own problems with these #otc #OTCQB Beauties  \n",
       "132621  @AlgyHall @Gallon73 @wheeliedealer @rcwhalen @HedgeyeTV @dlacalle_IA @Hedgeye @obone747 @MY21_Oracle @slarratt1 @Financial_Orbit @asibiza1 @marxnd @elerianm @TheIdleInvestor @ToddWenning @RobertStGeorge @RobertJShiller @Halsrethink @CiovaccoCapital @TheBubbleBubble @ReformedBroker @contrariansmind @MichaelSchuman @nickbatsford @ReutersJamie @M_McDonough @jonsanchezshow @DianaEPatterson @paul_dobson @KeithMcCullough @andrewrsorkin @FerroTV @MeganCBoxall @philjoakley @ShareScope @HW_MA @achildofthe70s @DVB99 @MacroPoloChina @followingeric @claudiohfox @groupstageexit @chumba54339270 @CarrRosie @marymcdougall13 @IChronicle @cfauk NEW🔥#TwinPetesInvesting #VIDEO #Podcast 51: #INVESTING #RISKS POSITION SIZING #FTSE #AIM #BITCOIN #CRYPTO #DOGECOIN #PSYCHOLOGY #PCA #AHT #BOTB #NWG #LLOY #BARC #DIVIDENDS #EQLS #MTFB #MMAG #CLIN #GTLY #CMRS #CUSN #ROO #AML #TPG #TRADING #SPREADBETTING &amp; https://t.co/FkrDWniXFE https://t.co/zWm6DWqk3p  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Longer character lengths from mentions -will be removed in future cleaning steps\n",
    "df[df[\"text\"].str.len() > 500].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a1290fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check missing \n",
    "miss = df.isnull().sum()\n",
    "miss[miss > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad3ab1a-45d7-4507-8c14-c794c1cad917",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range from 2021-02-05 10:52:04 to 2023-01-09 23:59:54\n"
     ]
    }
   ],
   "source": [
    "#Remove error rows preventing data conversion\n",
    "df = df.drop(df.loc[pd.to_datetime(df[\"date\"], errors = \"coerce\").isnull()].index, axis = \"index\")\n",
    "#Check date range\n",
    "print(\"Date range from \" + str(df['date'].min()) + \" to \" + str(df['date'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "054ac182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>770314</th>\n",
       "      <td>2021-08-08 12:28:01</td>\n",
       "      <td>#Bitcoin gonna tap 50K.  they were right. https://t.co/Z7T5vl3ulW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040180</th>\n",
       "      <td>2022-01-13 17:11:26</td>\n",
       "      <td>Tether value almost equals 1 US dollar\\n#Tether #cryptocurrecy #Bitcoin #Ethereum #cryptomev #cryptomevapp #CryptocurrencyNews #CryptoWireWatch #cryptocurrencies #SolanaAirdrop #Solana #NFTCommumity https://t.co/TO7Vbhl7wC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969091</th>\n",
       "      <td>2021-08-16 20:05:34</td>\n",
       "      <td>#Ethereum #bitcoin #CyberKongzVXNFTs #NFT NFT Gorillas Burned $90,000 Worth Of Ethereum Per Minute https://t.co/ngnMVW2r78 - dumbwire https://t.co/YHIuXFmXSQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153759</th>\n",
       "      <td>2022-01-22 13:12:17</td>\n",
       "      <td>#Bitcoin correction durations during larger impulsive uptrends.\\n\\n154 and 161 days\\n\\n280 and 105 days\\n\\n448 and 336 days (and counting) https://t.co/DZAgq1W5ZS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628118</th>\n",
       "      <td>2021-07-30 11:03:52</td>\n",
       "      <td>@cryptomedatech This is definitely going to be HUGE!  as the team has been an inspiration in their innovative effort and also they are hard working!!Must join!!\\n\\n@SHarianto17  @LiliGea2  @Hardidolay \\n \\n$TECH #NFTCommunity #nftcollector #CryptoNews #ADA #gamer #BTC #BSC #giveaway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "770314   2021-08-08 12:28:01   \n",
       "2040180  2022-01-13 17:11:26   \n",
       "969091   2021-08-16 20:05:34   \n",
       "2153759  2022-01-22 13:12:17   \n",
       "628118   2021-07-30 11:03:52   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                text  \n",
       "770314                                                                                                                                                                                                                             #Bitcoin gonna tap 50K.  they were right. https://t.co/Z7T5vl3ulW  \n",
       "2040180                                                               Tether value almost equals 1 US dollar\\n#Tether #cryptocurrecy #Bitcoin #Ethereum #cryptomev #cryptomevapp #CryptocurrencyNews #CryptoWireWatch #cryptocurrencies #SolanaAirdrop #Solana #NFTCommumity https://t.co/TO7Vbhl7wC  \n",
       "969091                                                                                                                                 #Ethereum #bitcoin #CyberKongzVXNFTs #NFT NFT Gorillas Burned $90,000 Worth Of Ethereum Per Minute https://t.co/ngnMVW2r78 - dumbwire https://t.co/YHIuXFmXSQ  \n",
       "2153759                                                                                                                           #Bitcoin correction durations during larger impulsive uptrends.\\n\\n154 and 161 days\\n\\n280 and 105 days\\n\\n448 and 336 days (and counting) https://t.co/DZAgq1W5ZS  \n",
       "628118   @cryptomedatech This is definitely going to be HUGE!  as the team has been an inspiration in their innovative effort and also they are hard working!!Must join!!\\n\\n@SHarianto17  @LiliGea2  @Hardidolay \\n \\n$TECH #NFTCommunity #nftcollector #CryptoNews #ADA #gamer #BTC #BSC #giveaway  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Approximately 130 spam observations\n",
    "check_spam = df.sample(n = 500, random_state = 147)\n",
    "check_spam.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a48fe15",
   "metadata": {},
   "source": [
    "#### Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a1c79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    '''Filtering steps prior to sampling including removing duplicates, high hashtag numbers/those including a high % of digits, and  \n",
    "    specific hashtags highly associated with spam'''\n",
    "    \n",
    "    #Get starting row numbers\n",
    "    initial_shape = df.shape[0]\n",
    "    \n",
    "    #Move to lower case\n",
    "    df[\"text\"] = df[\"text\"].str.lower()\n",
    "    \n",
    "    #Drop duplicate tweets\n",
    "    df[\"text\"] = df[\"text\"].drop_duplicates()\n",
    "    new_shape = df.shape[0]\n",
    "    removed = initial_shape - new_shape\n",
    "    print(\"Duplicate rows removed: \" + str(removed) + \"\\n\")\n",
    "    \n",
    "    #Spam associated words/hashtags/patterns\n",
    "    regex_patterns = [r'bitcoin price (usd):',\n",
    "                     r'giveaways',\n",
    "                     r'amazon',\n",
    "                     r'gift',\n",
    "                     r'#gaming',\n",
    "                     r'coinhuntworld',\n",
    "                     r'crypto prices (usd/₿)',\n",
    "                     r'scan results',\n",
    "                     r'#wanusdt',\n",
    "                     r'bitcoin - btc\\nprice:',\n",
    "                     r'#watchinwales',\n",
    "                     r'1 btc equals',\n",
    "                     r'bull alert!',\n",
    "                     r'move from unknown wallet',\n",
    "                     r'#betfurysuccess',\n",
    "                     r'#ethereum price update',\n",
    "                     r'airdrop',\n",
    "                     r'#btc_whale_alert',\n",
    "                     r'\\ndollar:',\n",
    "                     r'binancecoin price update',\n",
    "                     r'i-gaming',\n",
    "                     r'prices update',\n",
    "                     r'\\*\\*|\\*']\n",
    "                     \n",
    "                      \n",
    "                      \n",
    "    for pattern in regex_patterns:\n",
    "        df = df[~df[\"text\"].str.contains(pattern, na = False)]\n",
    "    \n",
    "    removed = new_shape - df.shape[0]\n",
    "    new_shape = df.shape[0]\n",
    "    print(\"Regex matches removed: \" + str(removed) + \"\\n\")\n",
    "    \n",
    "    #Filter high hashtag counts\n",
    "    df[\"hashtag_count\"] = df[\"text\"].str.count(\"#\")\n",
    "    df = df[df[\"hashtag_count\"] < 11]\n",
    "    \n",
    "    removed = new_shape - df.shape[0]\n",
    "    new_shape = df.shape[0]\n",
    "    print(\"High hashtags removed: \" + str(removed) + \"\\n\")\n",
    "    \n",
    "    #Remove observations with more than 35% digits\n",
    "    df[\"digits\"] = df[\"text\"].str.count(\"\\d\")/df[\"text\"].str.len()\n",
    "    df = df[df[\"digits\"] < 0.35]\n",
    "    \n",
    "    removed = new_shape - df.shape[0]\n",
    "    new_shape = df.shape[0]\n",
    "    print(\"High digits removed: \" + str(removed) + \"\\n\")\n",
    "    print(\"New observation total: \" + str(new_shape))\n",
    "    \n",
    "    #df.drop(columns = [\"hashtag_count\", \"digits\"])\n",
    "    \n",
    "    return df   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50df711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows removed: 0\n",
      "\n",
      "Regex matches removed: 542799\n",
      "\n",
      "High hashtags removed: 644340\n",
      "\n",
      "High digits removed: 6858\n",
      "\n",
      "New observation total: 3495291\n"
     ]
    }
   ],
   "source": [
    "df = filter_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80393fda-b27c-42e1-891b-1ea1872c2842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Convert date to datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "#Extract months \n",
    "df[\"month\"] = df[\"date\"].dt.to_period(\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48bca0cc-1fdb-43cc-ab44-1b39a63fb4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove missing values created from filtering\n",
    "df = df.dropna(subset = [\"text\"])\n",
    "miss = df.isnull().sum()\n",
    "miss[miss > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65d7eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unneeded columns\n",
    "df = df.drop(columns = [\"hashtag_count\", \"digits\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bdad03c-29f9-4928-9d67-32bdeb3eae1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only keep months with at least 5000 tweets\n",
    "filtered_df = df[df.groupby(\"month\")[\"month\"].transform(\"count\") > 500]\n",
    "filtered_df[\"month\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b73ad2-c766-410f-ad0b-8e83b4ed03dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sampled = filtered_df.groupby(\"month\").sample(n = 1000, random_state = 147).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "194490f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9954</td>\n",
       "      <td>shorting out\\n#btc \\n#bitcoin</td>\n",
       "      <td>2021-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1380</td>\n",
       "      <td>i called to break $44,578\\nhttps://t.co/poeyjufjk4\\nhttps://t.co/yddqwaltra\\n#bitcoin #btc #ethereum #eth #crypto… https://t.co/wqixuztj3e</td>\n",
       "      <td>2021-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35577</td>\n",
       "      <td>uniswap (uni), compound (comp), other defi coins are slipping lower  \\n\\n#btc #bitcoin #cryptocurrency #ethereum… https://t.co/esijvuxjej</td>\n",
       "      <td>2021-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6192</td>\n",
       "      <td>elon #musk ignites the #bitcoin rocket - https://t.co/jj8d7p7mhd\\n#tesla #bitcoin #btc #bitcoinnews #blockchain\\n\\nsup… https://t.co/0nje94sojb</td>\n",
       "      <td>2021-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8810</td>\n",
       "      <td>@elonmusk @tesla revelation of its bitcoin reserve will drive up the price but the amount of #bitcoin in possession… https://t.co/8a8dqix8dc</td>\n",
       "      <td>2021-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  \\\n",
       "0   9954   \n",
       "1   1380   \n",
       "2  35577   \n",
       "3   6192   \n",
       "4   8810   \n",
       "\n",
       "                                                                                                                                              text  \\\n",
       "0                                                                                                                    shorting out\\n#btc \\n#bitcoin   \n",
       "1       i called to break $44,578\\nhttps://t.co/poeyjufjk4\\nhttps://t.co/yddqwaltra\\n#bitcoin #btc #ethereum #eth #crypto… https://t.co/wqixuztj3e   \n",
       "2        uniswap (uni), compound (comp), other defi coins are slipping lower  \\n\\n#btc #bitcoin #cryptocurrency #ethereum… https://t.co/esijvuxjej   \n",
       "3  elon #musk ignites the #bitcoin rocket - https://t.co/jj8d7p7mhd\\n#tesla #bitcoin #btc #bitcoinnews #blockchain\\n\\nsup… https://t.co/0nje94sojb   \n",
       "4     @elonmusk @tesla revelation of its bitcoin reserve will drive up the price but the amount of #bitcoin in possession… https://t.co/8a8dqix8dc   \n",
       "\n",
       "     month  \n",
       "0  2021-02  \n",
       "1  2021-02  \n",
       "2  2021-02  \n",
       "3  2021-02  \n",
       "4  2021-02  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n"
     ]
    }
   ],
   "source": [
    "display(df_sampled.head())\n",
    "print(df_sampled.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b320f",
   "metadata": {},
   "source": [
    "#### Cleaning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6982e5a-2441-449c-a036-d592b5d52a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    ''' Applies cleaning steps to text including removing noise, removing stopwords, lemmatising, part of speech tagging \n",
    "    and tokenisation'''\n",
    "   \n",
    "    #Replace emojis with description\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    #Remove html\n",
    "    text = gensim.parsing.preprocessing.strip_tags(text)\n",
    "    \n",
    "    regex_patterns = [r'@\\w+', # Words after @ symbol\n",
    "                      r'\\n', #remaining tags\n",
    "                      r'http\\S+', #urls\n",
    "                      r'[^\\w\\s]',#Remove punctuation/symbols\n",
    "                      r'\\d'] #Remove digits\n",
    "    \n",
    "    \n",
    "    spelling_patterns = {r'\\b(bicoin|bittcoin|bitoin|btc|btcusd|btcusdt)\\b': 'bitcoin',\n",
    "                         r'\\busd\\b': 'dollars',\n",
    "                         r'\\bblock chain\\b': 'blockchain',\n",
    "                         r'\\bfincen\\b': 'finance', \n",
    "                         r'\\beth\\b': 'ethereum',\n",
    "                         r'\\b(crypto|crytocurrencies|cryptocoin)\\b': 'cryptocurrency',\n",
    "                         r'\\b(elon musk|elon|musk)\\b' :'elonmusk',\n",
    "                         r'\\b(bnb|binance coin)\\b' : 'binancecoin',\n",
    "                         r'\\b(nftart|nft art|nfts)\\b' : 'nft',\n",
    "                         r'\\b(to the moon|tothemoon)\\b' : 'moon',\n",
    "                         r'\\bada\\b': 'cardano',\n",
    "                         r'\\b(ma|macd)\\b' : 'movingaverage',\n",
    "                         r'\\bsats\\b': 'satoshis',\n",
    "                         r'\\b(th|thee)\\b' : 'the',\n",
    "                         r'\\b(doge| doge coin)\\b':'dogecoin'}\n",
    "    \n",
    "    #Remove with regex\n",
    "    for pattern in regex_patterns:\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "    \n",
    "    #Fix spelling\n",
    "    for pattern in spelling_patterns:\n",
    "        text = re.sub(pattern, spelling_patterns[pattern], text)\n",
    "        \n",
    "    #Remove non-english terms\n",
    "    text = ''.join(word for word in text if word.isascii())\n",
    "\n",
    "    #Expand out contractions\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    #Remove profanity\n",
    "    text = better_profanity.profanity.censor(text, \"\")\n",
    "    \n",
    "    #Remove extra whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd938a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_pipeline(text):    \n",
    "    \n",
    "    #Convert ot spacy doc\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    #POS to retain\n",
    "    tags = {\"NOUN\", \"ADJECTIVE\", \"VERB\"}\n",
    "    \n",
    "    #Apply spacy steps\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.pos_ in tags and len(token) > 1]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b7c6181-6068-4a1e-8029-d19aef1820fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 24000/24000 [16:15<00:00, 24.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 24000/24000 [03:23<00:00, 117.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>month</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9954</td>\n",
       "      <td>shorting out\\n#btc \\n#bitcoin</td>\n",
       "      <td>2021-02</td>\n",
       "      <td>shorting outbtc bitcoin</td>\n",
       "      <td>[short, btc, bitcoin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1380</td>\n",
       "      <td>i called to break $44,578\\nhttps://t.co/poeyjufjk4\\nhttps://t.co/yddqwaltra\\n#bitcoin #btc #ethereum #eth #crypto… https://t.co/wqixuztj3e</td>\n",
       "      <td>2021-02</td>\n",
       "      <td>i called to break  bitcoin ethereum ethereum cryptocurrency</td>\n",
       "      <td>[call, break, bitcoin, btc, ethereum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35577</td>\n",
       "      <td>uniswap (uni), compound (comp), other defi coins are slipping lower  \\n\\n#btc #bitcoin #cryptocurrency #ethereum… https://t.co/esijvuxjej</td>\n",
       "      <td>2021-02</td>\n",
       "      <td>uniswap uni compound comp other defi coins are slipping lower  bitcoin bitcoin cryptocurrency ethereum</td>\n",
       "      <td>[compound, comp, defi, coin, slip, btc, bitcoin, cryptocurrency, ethereum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6192</td>\n",
       "      <td>elon #musk ignites the #bitcoin rocket - https://t.co/jj8d7p7mhd\\n#tesla #bitcoin #btc #bitcoinnews #blockchain\\n\\nsup… https://t.co/0nje94sojb</td>\n",
       "      <td>2021-02</td>\n",
       "      <td>elonmusk ignites the bitcoin rocket   bitcoin bitcoin bitcoinnews blockchainsup</td>\n",
       "      <td>[musk, ignite, bitcoin, rocket, tesla, bitcoin, blockchain, sup, https://t.co/0nje94sojb]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8810</td>\n",
       "      <td>@elonmusk @tesla revelation of its bitcoin reserve will drive up the price but the amount of #bitcoin in possession… https://t.co/8a8dqix8dc</td>\n",
       "      <td>2021-02</td>\n",
       "      <td>revelation of its bitcoin reserve will drive up the price but the amount of bitcoin in possession</td>\n",
       "      <td>[@tesla, revelation, bitcoin, reserve, drive, price, bitcoin, possession]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  \\\n",
       "0   9954   \n",
       "1   1380   \n",
       "2  35577   \n",
       "3   6192   \n",
       "4   8810   \n",
       "\n",
       "                                                                                                                                              text  \\\n",
       "0                                                                                                                    shorting out\\n#btc \\n#bitcoin   \n",
       "1       i called to break $44,578\\nhttps://t.co/poeyjufjk4\\nhttps://t.co/yddqwaltra\\n#bitcoin #btc #ethereum #eth #crypto… https://t.co/wqixuztj3e   \n",
       "2        uniswap (uni), compound (comp), other defi coins are slipping lower  \\n\\n#btc #bitcoin #cryptocurrency #ethereum… https://t.co/esijvuxjej   \n",
       "3  elon #musk ignites the #bitcoin rocket - https://t.co/jj8d7p7mhd\\n#tesla #bitcoin #btc #bitcoinnews #blockchain\\n\\nsup… https://t.co/0nje94sojb   \n",
       "4     @elonmusk @tesla revelation of its bitcoin reserve will drive up the price but the amount of #bitcoin in possession… https://t.co/8a8dqix8dc   \n",
       "\n",
       "     month  \\\n",
       "0  2021-02   \n",
       "1  2021-02   \n",
       "2  2021-02   \n",
       "3  2021-02   \n",
       "4  2021-02   \n",
       "\n",
       "                                                                                               clean_text  \\\n",
       "0                                                                                 shorting outbtc bitcoin   \n",
       "1                                             i called to break  bitcoin ethereum ethereum cryptocurrency   \n",
       "2  uniswap uni compound comp other defi coins are slipping lower  bitcoin bitcoin cryptocurrency ethereum   \n",
       "3                         elonmusk ignites the bitcoin rocket   bitcoin bitcoin bitcoinnews blockchainsup   \n",
       "4       revelation of its bitcoin reserve will drive up the price but the amount of bitcoin in possession   \n",
       "\n",
       "                                                                                      tokens  \n",
       "0                                                                      [short, btc, bitcoin]  \n",
       "1                                                      [call, break, bitcoin, btc, ethereum]  \n",
       "2                 [compound, comp, defi, coin, slip, btc, bitcoin, cryptocurrency, ethereum]  \n",
       "3  [musk, ignite, bitcoin, rocket, tesla, bitcoin, blockchain, sup, https://t.co/0nje94sojb]  \n",
       "4                  [@tesla, revelation, bitcoin, reserve, drive, price, bitcoin, possession]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run cleaning pipelines\n",
    "df_sampled[\"clean_text\"] = df_sampled[\"text\"].progress_apply(clean_text)\n",
    "df_sampled[\"tokens\"] = df_sampled[\"text\"].progress_apply(spacy_pipeline)\n",
    "df_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9646eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save cleaned dataframe\n",
    "df_sampled.to_csv(\"./data/cleaned_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d74751",
   "metadata": {},
   "source": [
    "#### Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b04f33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.read_csv(\"./data/cleaned_data.csv\")\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56bd90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(df):\n",
    "    '''Returns sorted word counts from text'''\n",
    "    \n",
    "    #Get word freqs\n",
    "    words = chain.from_iterable(df[\"clean_text\"].str.split())\n",
    "    count = Counter(words)\n",
    "    \n",
    "    #create output df\n",
    "    output_df = pd.DataFrame(count.items(), columns = [\"Word\", \"Count\"])\n",
    "    \n",
    "    #Remove stopwords\n",
    "    output_df = output_df[~output_df[\"Word\"].isin(gensim.parsing.preprocessing.STOPWORDS)]\n",
    "    filter = output_df[\"Word\"] != \"\"\n",
    "    output_df = output_df[filter]\n",
    "    output_df = output_df.sort_values(by = \"Count\", ascending = False)\n",
    "    return output_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b46ede72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>32775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cryptocurrency</td>\n",
       "      <td>8705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ethereum</td>\n",
       "      <td>4718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>price</td>\n",
       "      <td>4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>k</td>\n",
       "      <td>1687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Count\n",
       "2           bitcoin  32775\n",
       "8    cryptocurrency   8705\n",
       "7          ethereum   4718\n",
       "32            price   4092\n",
       "552               k   1687"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get top word frequencies\n",
    "a =count_words(df_sampled)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3fe497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(bitcoin, bitcoin)           5163\n",
       "(bitcoin, ethereum)          1899\n",
       "(bitcoin, cryptocurrency)    1846\n",
       "(cryptocurrency, bitcoin)    1583\n",
       "(in, the)                    1213\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "#Get list of words in clean text\n",
    "list_text = [word for ob in df_sampled['clean_text'] for word in ob.split()]\n",
    "#Calculate the bigrams\n",
    "bigrams = nltk.ngrams(list_text, 2)\n",
    "#Get frequencies\n",
    "bigrams_freq = pd.Series(bigrams).value_counts()\n",
    "#Show the top bigrams\n",
    "display(bigrams_freq.head())        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be172c4",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ee105",
   "metadata": {},
   "source": [
    "The first model I chose to test was BERTopic, detailed in a paper by Maarten Grootendorst [[12]](#ref12). This offers a framework for topic modelling with different components which can be tested and adapted for the context of this problem. The first choice was how to generate word embeddings. While there are a host of models available for this, I chose to use the 'glove-twitter-25' embeddings, pre-trained using the GloVe model [[13]](#ref13). Given the size of my dataset, these have the advantage of significantly reducing the processing time required. They are also easily accessed through the 'gensim' library and should be suitable for use as they have been trained using a similar dataset of tweets.\n",
    "\n",
    "The model then reduces the dimensionality of embeddings using Uniform Manifold Approximation and Projection (UMAP) before applying a clustering algorithm to group the topics (HDBScan by default). As a hierarchical method this has the benefit of not requiring a predefined number of topics, and has been shown to be faster at processing a high number of observations than other methods [[14]]('#ref14'). However, as K-means has proven to be effective with similar data [[4]](#ref4), I will also include it in the tests. \n",
    "\n",
    "BERTopic can then use class based term frequency-inverse term frequency (ctf-idf) to find representations of the topics over time [[12 pg. ]](#ref12). This is shown in equation 1, showing the term frequencies (tf) per term (t) for each class (c) at each timestep (i), with A being the average words per class. \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  W_{t,c,i} = tf_{t,c,i}. log(1 + \\frac{A}{tf_t})\n",
    "\n",
    "\\end{equation}\n",
    "$$ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7525bed",
   "metadata": {},
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653aa628",
   "metadata": {},
   "source": [
    "In order to compare the models, some form of evaluation metric is required. However, as topic modelling is an unsupervised machine learning method there is no definitive method for determining the quality of the models. One potential method I considered was perplexity, which tests how well the model predicts new data. However, perplexity does not optimise for the interpretability of the topics themselves, which is important in gaining meaningful insights on Bitcoin [[13]](#ref13). \n",
    "\n",
    "Instead, I investigated the various metrics designed to measure coherence, or how interpretable the topics themselves are. Again many different methods exist, but I decided to use coherence value (c_v), as while its not the most computationally efficient method to calculate, it has been shown to correlate highly with human evaluation of topics [[14]](#ref14). Coherence value isn't currently available in the BERTopic library, so the code for calculating this was adapted from a solution posted by Maarten Grootendorst [[15]](#ref15).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0df329",
   "metadata": {},
   "source": [
    "#### BERTopic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df_sampled[\"clean_text\"].to_list()\n",
    "\n",
    "#Clustering model\n",
    "cluster_model = HDBSCAN(prediction_data = True, min_cluster_size = 10)\n",
    "\n",
    "#ctf-idf model\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get pre-trained embeddings\n",
    "glove_embeddings = api.load(\"glove-twitter-25\")\n",
    "\n",
    "#Create model\n",
    "bertopic_model = BERTopic(embedding_model = glove_embeddings, ctfidf_model = ctfidf_model, \n",
    "                          verbose = True, calculate_probabilities = True, nr_topics=\"auto\")\n",
    "topics, probabilites = bertopic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccde4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code adapted from snippet by Maarten Grootendorst, reference [17].  \n",
    "\n",
    "# Preprocess Documents\n",
    "documents = pd.DataFrame({\"Document\": docs,\n",
    "                          \"ID\": range(len(docs)),\n",
    "                          \"Topic\": topics})\n",
    "documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\n",
    "cleaned_docs = bertopic_model._preprocess_text(documents_per_topic.Document.values)\n",
    "\n",
    "# Extract vectorizer and analyzer from BERTopic\n",
    "vectorizer = bertopic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "# Extract features for Topic Coherence evaluation\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topic_words = [[words for words, _ in bertopic_model.get_topic(topic)] \n",
    "               for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed15b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get topics\n",
    "topic_info = bertopic_model.get_topic_info()\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bca7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show topic clustering\n",
    "bertopic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show topic groups\n",
    "bertopic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model over time\n",
    "#Get dates\n",
    "dates = df_sampled[\"month\"].to_list()\n",
    "dynamic_topics = bertopic_model.topics_over_time(docs, dates, global_tuning = True, evolution_tuning = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab312908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Timeseries topics\n",
    "bertopic_model.visualize_topics_over_time(dynamic_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1058d935",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65dcd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "First results with BERTopic produced 182 topics, visualisation showing a great deal of overlap between different \n",
    "\n",
    "#first - 182, 0.68, lots of overlap, \n",
    "#reduce topics - 40 - 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table of topics returned - model one/model 2 etc\n",
    "- coherence scores \n",
    "\n",
    "- BERTopic visualisations - cluster of topics \n",
    "\n",
    "Graph topics over time vs price changes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e96ae4",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03825a03",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "There are limitations to this research. Issues with the quality of the data lead to spam posts being retained even after the cleaning processes. With additional time and further research a full machine learning model could be implemented to more accurately detect and remove spam from the corpus prior to modelling. This would help uncover the pertinent information on Bitcoin hidden in the text. \n",
    "\n",
    "Further work could also examine the sentiment of \n",
    "\n",
    "While coherence gives a quantifiable method for comparing models, the true test of the model's usefulness is whether the resulting topics stand up to human judgement. While I have gauged the output, this is best conducted by domain area experts, potentially using the 'word intrusion' method. This involves adding an additional word to the topics and testing if participants can identify the intruder, which should be easier for a cohensive and well defined topic than a random one. This is a measurable evaluation of quality in what might else be subjective opinion. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93658608",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa7922-1ec0-484e-bb81-f0593de7668e",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82571dc3-c532-4b3f-8a99-b01af34d1916",
   "metadata": {},
   "source": [
    "<a id='ref1'></a> [1] Burell, T and Aju, M. Research Note: Cryptoassets consumer research 2023 (Wave 4). Available from:\n",
    "https://www.fca.org.uk/publication/research-notes/research-note-cryptoasset-consumer-research-2023-wave4.pdf, 2023.\n",
    "\n",
    "<a id='ref2'></a> [2] Liana Badea and Mariana Claudia Mungiu-Pupzan. The economic and environmental impact of bitcoin. IEEE access, 9:48091–48104, 2021\n",
    "\n",
    "<a id='ref3'></a> [3] Qiao F, Williams J. Topic modelling and sentiment analysis of global warming tweets: Evidence from big data analysis. Journal of Organizational and End User Computing (JOEUC). 2022 May 1;34(3):1-8.\n",
    "\n",
    "<a id='ref4'></a> [4] Marco Ortu, Stefano Vacca, Giuseppe Destefanis, and Claudio Conversano. Cryptocurrency ecosystems and social media environments: An empirical analysis through hawkes’ models and natural language processing. Machine\n",
    "Learning with Applications, 7:100229, 2022\n",
    "\n",
    "\n",
    "<a id='ref5'></a> [5]  Stephan A Curiskis, Barry Drake, Thomas R Osborn, and Paul J Kennedy.An evaluation of document clustering and topic modelling in two online social networks: Twitter and reddit. Information Processing & Management,57(2):102034, 2020.\n",
    "\n",
    "<a id='ref6'></a> [6] Andrew Burnie and Emine Yilmaz. An analysis of the change in discussions on social media with bitcoin price. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 889–892, 2019.\n",
    "\n",
    "<a id='ref7'></a> [7]  Roman Egger and Joanne Yu. A topic modeling comparison between lda, nmf, top2vec, and bertopic to demystify twitter posts. Frontiers in sociology, 7:886498, 2022.\n",
    "\n",
    "<a id='ref8'></a> [8] Belal Abdullah Hezam Murshed, Suresha Mallappa, Osamah AM Ghaleb, and Hasib Daowd Esmail Al-ariki. Efficient twitter data cleansing model for data analysis of the pandemic tweets. Emerging Technologies During the Era of COVID-19 Pandemic, pages 93–114, 2021.\n",
    "\n",
    "<a id='ref9'></a> [9] Kaggle. bitcoin tweets.csv. Available from: https://www.kaggle.com/datasets/kaushiksuresh147/bitcoin-tweets, 2023. Accessed: 2024 June 2nd.\n",
    "\n",
    "<a id='ref10'></a> [10] Nan Sun, Guanjun Lin, Junyang Qiu, and Paul Rimba. Near real-time twitter spam detection with machine learning techniques. International Journal of Computers and Applications, 44(4):338–348, 2022.\n",
    "\n",
    "\n",
    "<a id='ref11'></a> [11] Nicholas Reimann. Twitter Boosts Character Limit To 4,000 For Twitter Blue Subscribers. Forbes. Available from: https://www.forbes.com/sites/nicholasreimann/2023/02/08/twitter-boosts-character-limit-to-4000-for-twitter-blue-subscribers/. Accessed:2024 June 2nd.\n",
    "\n",
    "\n",
    "<a id='ref12'></a> [12] Bitcoin price dataset (2017-2023). Available from:https://www.kaggle.com/datasets/jkraak/bitcoin-price-dataset, 2023. Data originally sourced from Binance API. Accessed: 2024 June 5th.\n",
    "\n",
    "<a id='ref13'></a> [13] Maarten Grootendorst. Bertopic: Neural topic modeling with a class-based\n",
    "tf-idf procedure. arXiv preprint arXiv:2203.05794, 2022.\n",
    "\n",
    "<a id='ref13'></a> [14] Leland McInnes and John Healy. Accelerated hierarchical density based clustering. In 2017 IEEE international conference on data mining workshops (ICDMW), pages 33–42. IEEE, 2017.\n",
    "\n",
    "<a id='ref15'></a> [15] Jeffrey Pennington, Richard Socher, and Christopher D. Manning. Glove: Global vectors for word representation. In Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543, 2014.\n",
    "\n",
    "<a id='ref15'></a> [15]  Maarten Grootendorst. Code snippet: Coherence value from BERTopic (2021 April 16). {Available from: https://github.com/MaartenGr/BERTopic/issues/90#issuecomment-820915389, 2021. Accessed: 2024 June 6th. \n",
    "\n",
    "<a id='ref16'></a> [16] Abdelrazek A, Eid Y, Gawish E, Medhat W, Hassan A. Topic modeling algorithms and applications: A survey. Information Systems . 2023 Feb 1 [cited 2024 May 22]; 112: Article number 102131. Available from: https://doi.org/10.1016/j.is.2022.102131\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757e4c6-e23e-4649-8bc5-9542536ab5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
